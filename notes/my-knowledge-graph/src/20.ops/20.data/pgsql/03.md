# PostgreSQL 几个重要概念



## 一、锁机制

在了解 PostgreSQL 锁之前，我们需要了解锁存在的意义是啥？

当多个会话同时访问数据库的同一数据时，理想状态是为所有会话提供高效的访问，同时还要维护严格的数据一致性。那数据一致性通过什么来维护呢，就是通过 `MVCC（多版本并发控制）` 。

`MVCC（多版本并发控制）`：每个SQL语句看到的都只是当前事务开始的数据快照，而不管底层数据的当前状态。

这样可以保护语句不会看到在相同数据上由其他连接执行更新的并发事务造成的不一致数据，为每一个数据库会话提供事务隔离。MVCC 避免了传统的数据库系统的锁定方法，将通过锁争夺最小化的方法来达到多会话并发访问时的性能最大化目的。

锁机制在 PostgreSQL 里非常重要 (对于其他现代的 RDBMS 也是如此)。对于数据库应用程序开发者（特别是那些涉及到高并发代码的程序员），需要对锁非常熟悉。对于某些问题，锁需要被重点关注与检查。大部分情况，这些问题跟死锁或者数据不一致有关系，基本上都是由于对 Postgres 的锁机制不太了解导致的。虽然锁机制在 Postgres 内部很重要，但是文档缺非常缺乏，有时甚至还是错误的，与文档所指出的结果不一致。我会告诉你精通 Postgres 的锁机制需要知道的一切，要知道对锁了解的越多，解决与锁相关的问题就会越快。

`PostgreSQL` 提供了多种锁模式用于控制对表中数据的并发访问，其中最主要的是`表级锁`与`行级锁`，除此之外还有`页级锁`、`咨询锁`等等，接下来主要介绍表级锁与行级锁。

### 表级锁

表级锁通常会在执行各种命令执行时自动获取，或者通过在事务中使用`LOCK语句`显示获取。

每种锁都有自己的冲突集合。

`表级锁`：两个事务在同一时刻不能在同一个表上持有互相冲突的锁，但是可以同时持有不冲突的锁。

表级锁共有八种模式，其存在于PG的`共享内存中`，可以通过 `pg_locks` 系统视图查阅。

#### ACCESS SHARE 访问共享

`SELECT` 命令在被引用的表上会获得一个这种模式的锁。通常，任何只读取表而不修改它的查询都将获取这种表模式。

#### ROW SHARE 行共享

`SELECT FOR UPDATE` 和 `SELECT FOR SHARE` 命令在目标表上会获得一个这种模式的锁。（加上在被引用但没有选择 `FOR UPDATE` / `FOR SHARE` 的任何其他表上的 ACCESS SHARE 锁。）

#### ROW EXCLUSIVE 行独占

`UPDATE`、`DELETE` 和 `INSERT` 命令在目标表上会获得一个这种模式的锁。（加上在任何其他被引用表上的 ACCESS SHARE锁。）通常，这种锁模式将被任何修改表中数据的命令取得。

#### SHARE UPDATE EXCLUSIVE 共享更新独占

`VACUUM（不带FULL）`、`ANALYZE`、`CREATE INDEX CONCURRENTLY`、`REINDEX CONCURRENTLY`、`CREATE STATISTICS` 命令以及某些 `ALTER INDEX` 和 `ALTER TABLE` 命令的变体会获得。这种模式保护一个表不受并发模式改变和 VACUUM 运行的影响。

#### SHARE 共享

`CREATE INDEX（不带CONCURRENTLY）` 命令会获得。

这种模式保护一个表不受并发数据改变的影响。

#### SHARE ROW EXCLUSIVE 共享行独占

`CREATE TRIGGER` 命令和某些形式的 `ALTER TABLE` 命令会获得。

这种模式保护一个表不受并发数据修改所影响，并且是自排他的，这样在同一个时刻只能有一个会话持有它。

#### EXCLUSIVE 排他

`REFRESH METERIALIZED VIEW CONCURRENTLY` 命令会获得。

这种模式只允许并发的ACCESS SHARE锁，即只有来自于表的读操作可以与一个持有该锁模式的事务并行处理。

#### ACCESS EXCLUSIVE 访问独占

`ALTER TABLE`、`DROP TABLE`、`TRUNCATE`、`REINDEX`、`CLUSTER`、`VACUUM FULL` 和 `REFRESH MATERIALIZED VIEW（不带CONCURRENTLY）`命令会获得。很多形式的 `ALTER INDEX` 和 `ALTER TABLE` 也在这个层面上获得锁。这也是未显式指定模式的 `LOCK TABLE` 命令的默认锁模式。

这种模式与所有模式的锁冲突。这种模式保持者是访问该表的唯一事务。

我们下面举两个例子说明一下：

#### 示例一

当一个会话运行了 `update` 语句，此时会话表上的锁模式为 `ROW EXCLUSIVE`，从上图我们可以看出 `ROW EXCLUSIVE` 与 `SHARE`、`SHARE ROW`、`ROW EXCLUSIVE`、`EXCLUSIVE` 和 `ACCESS EXCLUSIVE` 锁模式冲突。

也就是说在这个会话未提交事务释放锁之前，我们不能做申请 `SHARE`、`SHARE ROW`、`ROW EXCLUSIVE`、`EXCLUSIVE` 和 `ACCESS EXCLUSIVE` 锁模式相关的操作，例如 `CREATE INDEX（不带CONCURRENTLY）`、`ALTER TABLE`、`DROP TABLE`、`TRUNCATE`、`REINDEX`、`CLUSTER`、`VACUUM FULL` 和 `REFRESH MATERIALIZED VIEW（不带CONCURRENTLY）`等。

我们先创建一个测试数据库：

```
# 创建测试用户
create user root password 'root';
# 创建测试数据库
create database mydb owner root encoding UTF8;
# 创建和测试用户同名Schema
create schema AUTHORIZATION CURRENT_USER;
```

我们创建一张测试表 `t_user`，并插入一条测试数据：

```
create table "t_user" (
 "id" bigserial not null,
 "username" varchar (64) not null,
 constraint t_user_pk primary key (id)
);
insert into t_user values(1, 'ACGkaka');
```

**会话一：** 执行 `update` 语句。

```
begin;
update t_user set username='ACGkaka1' where id=1;
```

**会话二：** 执行 `alter table` 语句，这时会处于等待状态。

```
alter table t_user add dept_no int;
```

执行SQL，查看锁等待情况：（SQL参考`附录一`）

注：`Lock_Granted: true`即为堵塞源。

直到“会话一”结束，“会话二”语句才执行成功。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsYk6LJNodZkqm67Diavrq29fjtr7lj580gWYkQQe3xD0U7h8K6uXYy7w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsNpb3fuicWLO1YVyp2mIyfC0A1HicfVT5sIqWtlbT7H1PF7Ud5ruVl4Jw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsSaArFobDc1xFOsvlNwcjficeEbuCYWJ6xmI282bGJibzT8ObgLiad7ib8w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 示例二

当一个会话运行了 `truncate` 语句，此时会话表上的锁模式为 `ACCESS EXCLUSIVE`，从图上我们可以看到这种模式和所有的锁模式都冲突。这意味着在当前会话未结束之前，这个表上的其他操作都做不了。

**会话一：** 执行 `truncate` 语句。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsZbrUQecphjibVDpsk3O8o59UydmC43Lh7F1AiarP23n6eT3CoIZrNiaYA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)**会话二：** 执行 `select` 语句时处于等待状态。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXs7kuUs6yGjhz3FwbSZS97lH40zItjKT7lIQlR1ksNBIiavLGmgWKuJUg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)执行SQL，查看锁等待情况：（SQL参考`附录一`）![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsLBg4KaPdndtMxM5NibWhibffDzGZAon960kWiat4yQB5fQd8F02vP0NVw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)注：`Lock_Granted: true`即为堵塞源。

直到“会话一”结束，“会话二”语句才执行成功。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsk8ntEywI1huibvvKm6vwHOCZCO4plPfyEtoclWjyTvVGbNzbqibicKRNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsibmHCbIicmicicic7xwPyy4xFGODzlia4yCAgjnKiaX4UMcgtRhejjJ4KI19g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)通过上面2个示例，应该都比较了解各种锁模式冲突的情况了，接下来我们介绍行级锁。

### 行级锁

`行级锁`：同一个事务可能会在相同的行上保持冲突的锁，甚至是在不同的子事务中。但是除此之外，两个事务永远不可能在相同的行上持有冲突的锁。

行级锁不影响数据查询，它们只阻塞对同一行的写入者和加锁者。行级锁在事务结束时或保存点回滚的时候释放，就像表级锁一样。下面是常用的行级锁模式：

#### FOR UPDATE 更新

`FOR UPDATE` 会导致由 `SELECT` 语句检索到的行被锁定，就好像它们要被更新。这可以阻止它们被其他事务锁定、修改或者删除，直到当前事务结束。

也就是说其他尝试 `UPDATE`、`DELETE`、`SELECT FOR UPDATE`、`SELECT FOR NO KEY UPDATE`、`SELECT FOR SHARE` 或者 `SELECT FOR KEY SHARE` 这些行的事务将被阻塞，直到当前事务结束。

反过来，SELECT FOR UPDATE 将等待已经在相同行上运行以上这些命令的并发事务，并且接着锁定并且返回被更新的行（或者没有行，因为行可能已被删除）。

#### FOR NO KEY UPDATE 无键更新

行为与 `FOR UPDATE` 类似，不过获得的锁较弱，这种锁将不会阻塞尝试在相同行上获得锁的 `SELECT FOR KEY SHARE` 命令。任何不获取 `FOR UPDATE` 锁的 `UPDATE` 也会获得这种锁模式。

#### FOR SHARE 共享

行为与 `FOR NO KEY UPDATE` 类似，不过它在每个检索到的杭上获得一个`共享锁`而不是`排他锁`。

一个共享锁会阻塞其他食物在这些行上执行 `UPDATE`、`DELETE`、`SELECT FOR UPDATE` 或者 `SELECT FOR NO KEY UPDATE`，但是它不会阻止它们执行 `SELECT FOR SHARE` 或者 `SELECT FRO KEY SHARE`。

### FOR KEY SHARE 键共享

行为与 `FOR SHARE` 类似，不过锁较弱，`SELECT FOR UPDATE` 会被阻塞，但是 `SELECT FOR NO KEY UPDATE` 不会被阻塞，一个键共享锁会阻塞其他事务执行修改键值的 `DELETE` 或者 `UPDATE`，但不会阻塞其他 `UPDATE`，也不会阻止 `SELECT FOR NO KEY UPDATE`、`SELECT FOR SHARE` 或者 `SELECT FOR KEY SHARE`。



### 4 个执行语句 timeout 参数

#### lock_timeout

`lock_timeout`：获取一个表，索引，行上的锁超过这个时间，直接报错，不等待，0为禁用。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsUEPSk0j8WQGXs5ibobNYr8RsdR7U5jO3lUkQk7J6LQ3gEhFAiafgUwbQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### statement_timeout

`statement_timeout`：当SQL语句的执行时间超过这个设置时间，终止执行SQL，0为禁用。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsMuul4CLCXanUfcMeCsEvPGe8ibGKUun3DwsPRmYnPowh7ibg0Xm93GuA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### idle_in_transaction_session_timeout

`idle_in_transaction_session_timeout`：在一个空闲的事务中，空闲时间超过这个值，将视为超时，0为禁用。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXshgx4viasoe57EWyAT7AVmDfeDvpBYkCDnVicV4d9q6eLib9QlmFRLmd6w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### deadlock_timeout

`dealdlock_timeout`：死锁时间超过这个值将直接报错，不会等待，默认设置为1s。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsznunSbdWWgsI51g7L2qLLRv6vTiak55RYOia7hJljPyjiaI9wqoDgftAQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

### 页级锁

除了表级别和行级别的锁以外，页面级别的共享/排他锁被用来控制对共享缓冲池中表页面的读/写。 这些锁在行被抓取或者更新后马上被释放。应用开发者通常不需要关心页级锁，我们在这里提到它们只是为了完整。

### 劝告锁

Postgres提供创建具有应用定义的锁的方法，这些被称为劝告锁（advisory locks），因为系统并不支持其使用，其取决于应用对锁的正确使用。

Postgres 中有两种途径可以获得一个劝告锁：会话层级或事务层级。一旦在会话层级获得劝告锁，会一直保持到被显式释放或会话结束。不同于标准的锁请求，会话层级的劝告锁请求并不遵守事务语义：事务被回滚后锁也会随着回滚保持着，同样地即使调用锁的事务之后失败了，解锁请求仍然是有效的。一个锁可以被拥有它的进程多次获取；对于每个完成的锁请求，在锁被真正释放前一定要有一个对应的解锁请求。

另一方面，事务层级的锁请求表现得更像普通的锁请求：它们在事务结束时会自动释放，并且没有显式的解锁操作。对于短暂地使用劝告锁，这种特性通常比会话层级更方便。可以想见，会话层级与事务层级请求同一个劝告锁标识符会互相阻塞。如果一个会话已经有了一个劝告锁，它再请求时总会成功的，即使其他会话在等待此锁；不论保持现有的锁和新的请求是会话层级还是事务层级，都是这样。文档中可以找到操作劝告锁的完整函数列表。

这里有几个获取事务层级劝告锁的例子（pg_locks是系统视图，文章之后会说明。它存有事务保持的表级锁和劝告锁的信息）：

启动第一个psql会话，开始一个事务并获取一个劝告锁：

```
-- Transaction 1
BEGIN; SELECT pg_advisory_xact_lock(1); 
-- Some work here
```

现在启动第二个psql会话并在同一个劝告锁上执行一个新的事务：

```
-- Transaction 2
BEGIN; SELECT pg_advisory_xact_lock(1);
-- This transaction is now blocked
```

在第三个psql会话里我们可以看下这个锁现在的情况：

```
SELECT * FROM pg_locks;-- Only relevant parts of output
   locktype    | database | relation | page | tuple | virtualxid | transactionid | classid | objid | objsubid | virtualtransaction |  pid  |        mode         | granted |fastpath---------------+----------+----------+------+-------+------------+---------------+---------+-------+----------+--------------------+-------+---------------------+---------+----------
    advisory   |    16393 |          |      |       |            |               |       0 |     1 |        1 | 4/36               |  1360 | ExclusiveLock       | f       | f
    advisory   |    16393 |          |      |       |            |               |       0 |     1 |        1 | 3/186              | 14340 | ExclusiveLock       | t       | f
-- Transaction 1
COMMIT;
-- This transaction now released lock, so Transaction 2 can continue
```

我们同样可以调用获取锁的非阻塞方法，这些方法会尝试去获取锁，并返回true（如果成功了）或者false（如果无法获取锁）。

```
-- Transaction 1
BEGIN;
SELECT pg_advisory_xact_lock(1);
-- Some work here
-- Transaction 2
BEGIN;
SELECT pg_try_advisory_xact_lock(1) INTO vLockAcquired;
IF vLockAcquired THEN
-- Some work
ELSE
-- Lock not acquired
END IF;
-- Transaction 1
COMMIT;
```



### 监控锁

所有活动事务持有的监控锁的基本配置即为系统视图 pg_locks。这个视图为每个可加锁的对象、已请求的锁模式和相关事务包含一行记录。非常重要的一点是，pg_locks 持有内存中被跟踪的锁的信息，所以它不显示行级锁！（译注：据查以前的文档，有关行级锁的信息是存在磁盘上，而非内存）这个视图显示表级锁和劝告锁。如果一个事务在等待一个行级锁，它通常在视图中显示为在等待该行级锁的当前所有者的固定事务 ID。这使得调试行级锁更为困难。事实上，在任何地方你都看不到行级锁，直到有人阻塞了持有此锁的事务（然后你在 pg_locks 表里可以看到一个被上锁的元组）。pg_locks 是可读性欠佳的视图（不是很人性化），所以我们来让显示锁定信息的视图更好接受些：

```
-- View with readable locks info and filtered out locks on system tables
CREATE VIEW active_locks AS
SELECT clock_timestamp(), pg_class.relname, pg_locks.locktype, pg_locks.database,
       pg_locks.relation, pg_locks.page, pg_locks.tuple, pg_locks.virtualtransaction,
       pg_locks.pid, pg_locks.mode, pg_locks.granted
FROM pg_locks JOIN pg_class ON pg_locks.relation = pg_class.oid
WHERE relname !~ '^pg_' and relname <> 'active_locks';
-- Now when we want to see locks just type
SELECT * FROM active_locks;
--查看会话session
select pg_backend_pid();

--查看会话持有的锁
select * from pg_locks where pid=3797;

--1,查看数据库
select  pg_database.datname, pg_database_size(pg_database.datname) AS size from pg_database; //查询所有数据库,及其所占空间大小

--2. 查询存在锁的数据表
select a.locktype,a.database,a.pid,a.mode,a.relation,b.relname -- ,sa.*
from pg_locks a
join pg_class b on a.relation = b.oid 
inner join  pg_stat_activity sa on a.pid=sa.procpid

--3.查询某个表内,状态为lock的锁及关联的查询语句
select a.locktype,a.database,a.pid,a.mode,a.relation,b.relname -- ,sa.*
from pg_locks a
join pg_class b on a.relation = b.oid 
inner join  pg_stat_activity sa on a.pid=sa.procpid
where a.database=382790774  and sa.waiting_reason='lock'
order by sa.query_start

--4.查看数据库表大小
select pg_database_size('playboy');
--查看会话被谁阻塞
select pg_blocking_pids(3386);
```

### 死锁

显式锁定的使用可能会增加死锁的可能性，死锁是指两个（或多个）事务相互持有对方想要的锁。

例如，如果事务 1 在表 A 上获得一个排他锁，同时试图获取一个在表 B 上的排他锁， 而事务 2 已经持有表 B 的排他锁，同时却正在请求表 A 上的一个排他锁，那么两个事务就都不能进行下去。PostgreSQL能够自动检测到死锁情况 并且会通过中断其中一个事务从而允许其它事务完成来解决这个问题（具体哪个事务会被中 断是很难预测的，而且也不应该依靠这样的预测）。

要注意死锁也可能会作为行级锁的结果而发生（并且因此，它们即使在没有使用显式锁定的情况下也会发生)。考虑如下情况，两个并发事务在修改一个表。第一个事务执行：

```
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 11111; 
```

这样就在指定帐号的行上获得了一个行级锁。然后，第二个事务执行：

```
UPDATE accounts SET balance = balance + 100.00 WHERE acctnum = 22222; 
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 11111;
```

第一个UPDATE语句成功地在指定行上获得了一个行级锁，因此它成功更新了该行。 但是第
二个UPDATE语句发现它试图更新的行已经被锁住了，因此它等待持有该锁的事务结束。事
务二现在就在等待事务一结束，然后再继续执行。现在，事务一执行：

```
UPDATE accounts SET balance = balance - 100.00 WHERE acctnum = 22222;
```

事务一试图在指定行上获得一个行级锁，但是它得不到：事务二已经持有了这样的锁。所以
它要等待事务二完成。因此，事务一被事务二阻塞，而事务二也被事务一阻塞：一个死锁。
PostgreSQL将检测这样的情况并中断其中一个事务。

防止死锁的最好方法通常是保证所有使用一个数据库的应用都以一致的顺序在多个对象上获得锁。在上面的例子里，如果两个事务以同样的顺序更新那些行，那么就不会发生死锁。 我们也应该保证一个事务中在一个对象上获得的第一个锁是该对象需要的最严格的锁模式。如果我们无法提前验证这些，那么可以通过重试因死锁而中断的事务来即时处理死锁。

只要没有检测到死锁情况，寻求一个表级或行级锁的事务将无限等待冲突锁被释放。这意味着一个应用长时间保持事务开启不是什么好事（例如等待用户输入）。



## 附录

#### 附录一：查看锁等待情况SQL

```
with
 t_wait as
 (
 select a.mode,a.locktype,a.database,a.relation,a.page,a.tuple,a.classid,a.granted,
  a.objid,a.objsubid,a.pid,a.virtualtransaction,a.virtualxid,a.transactionid,a.fastpath,
  b.state,b.query,b.xact_start,b.query_start,b.usename,b.datname,b.client_addr,b.client_port,b.application_name
 from pg_locks a,pg_stat_activity b where a.pid=b.pid and not a.granted
 ),
 t_run as
 (
 select a.mode,a.locktype,a.database,a.relation,a.page,a.tuple,a.classid,a.granted,
  a.objid,a.objsubid,a.pid,a.virtualtransaction,a.virtualxid,a.transactionid,a.fastpath,
  b.state,b.query,b.xact_start,b.query_start,b.usename,b.datname,b.client_addr,b.client_port,b.application_name
 from pg_locks a,pg_stat_activity b where a.pid=b.pid and a.granted
 ),
 t_overlap as
 (
 select r.* from t_wait w join t_run r on
  (
  r.locktype is not distinct from w.locktype and
  r.database is not distinct from w.database and
  r.relation is not distinct from w.relation and
  r.page is not distinct from w.page and
  r.tuple is not distinct from w.tuple and
  r.virtualxid is not distinct from w.virtualxid and
  r.transactionid is not distinct from w.transactionid and
  r.classid is not distinct from w.classid and
  r.objid is not distinct from w.objid and
  r.objsubid is not distinct from w.objsubid and
  r.pid <> w.pid
  )
 ),
 t_unionall as
 (
 select r.* from t_overlap r
 union all
 select w.* from t_wait w
 )
 select locktype,datname,relation::regclass,page,tuple,virtualxid,transactionid::text,classid::regclass,objid,objsubid,
  string_agg(
   'Pid: '||case when pid is null then 'NULL' else pid::text end||chr(10)||
   'Lock_Granted: '||case when granted is null then 'NULL' else granted::text end||' , Mode: '||case when mode is null then 'NULL' else mode::text end||' , FastPath: '||case when fastpath is null then 'NULL' else fastpath::text end||' , VirtualTransaction: '||case when virtualtransaction is null then 'NULL' else virtualtransaction::text end||' , Session_State: '||case when state is null then 'NULL' else state::text end||chr(10)||
   'Username: '||case when usename is null then 'NULL' else usename::text end||' , Database: '||case when datname is null then 'NULL' else datname::text end||' , Client_Addr: '||case when client_addr is null then 'NULL' else client_addr::text end||' , Client_Port: '||case when client_port is null then 'NULL' else client_port::text end||' , Application_Name: '||case when application_name is null then 'NULL' else application_name::text end||chr(10)||
   'Xact_Start: '||case when xact_start is null then 'NULL' else xact_start::text end||' , Query_Start: '||case when query_start is null then 'NULL' else query_start::text end||' , Xact_Elapse: '||case when (now()-xact_start) is null then 'NULL' else (now()-xact_start)::text end||' , Query_Elapse: '||case when (now()-query_start) is null then 'NULL' else (now()-query_start)::text end||chr(10)||
   'SQL (Current SQL in Transaction): '||chr(10)||
   case when query is null then 'NULL' else query::text end,
   chr(10)||'--------'||chr(10)
  order by
   ( case mode
   when 'INVALID' then 0
   when 'AccessShareLock' then 1
   when 'RowShareLock' then 2
   when 'RowExclusiveLock' then 3
   when 'ShareUpdateExclusiveLock' then 4
   when 'ShareLock' then 5
   when 'ShareRowExclusiveLock' then 6
   when 'ExclusiveLock' then 7
   when 'AccessExclusiveLock' then 8
   else 0
   end  ) desc,
   (case when granted then 0 else 1 end)
  ) as lock_conflict
 from t_unionall
 group by
  locktype,datname,relation,page,tuple,virtualxid,transactionid::text,classid,objid,objsubid ;
```

输出结果格式如下：![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsTzgiadVvyLEh9jKJeiba9EI1c1kuFpfGqUTzMCBkXORq4KjspB7FlLPg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 附录二：查看阻塞会话，并生成kill sql

```
SELECT pg_cancel_backend(pid); – session还在，事物回退;
SELECT pg_terminate_backend(pid); --session消失，事物回退
with recursive 
tmp_lock as (
 select distinct
  --w.mode w_mode,w.page w_page,
  --w.tuple w_tuple,w.xact_start w_xact_start,w.query_start w_query_start,
  --now()-w.query_start w_locktime,w.query w_query
  w.pid as id,--w_pid,
  r.pid as parentid--r_pid,
  --r.locktype,r.mode r_mode,r.usename r_user,r.datname r_db,
  --r.relation::regclass,
  --r.page r_page,r.tuple r_tuple,r.xact_start r_xact_start,
  --r.query_start r_query_start,
  --now()-r.query_start r_locktime,r.query r_query,
 from (
  select a.mode,a.locktype,a.database,
  a.relation,a.page,a.tuple,a.classid,
  a.objid,a.objsubid,a.pid,a.virtualtransaction,a.virtualxid,
  a.transactionid,
  b.query as query,
  b.xact_start,b.query_start,b.usename,b.datname
  from pg_locks a,
  pg_stat_activity b
  where a.pid=b.pid
  and not a.granted
 ) w,
 (
  select a.mode,a.locktype,a.database,
  a.relation,a.page,a.tuple,a.classid,
  a.objid,a.objsubid,a.pid,a.virtualtransaction,a.virtualxid,
  a.transactionid,
  b.query as query,
  b.xact_start,b.query_start,b.usename,b.datname
  from pg_locks a,
  pg_stat_activity b -- select pg_typeof(pid) from pg_stat_activity
  where a.pid=b.pid
  and a.granted
 ) r
 where 1=1
  and r.locktype is not distinct from w.locktype
  and r.database is not distinct from w.database
  and r.relation is not distinct from w.relation
  and r.page is not distinct from w.page
  and r.tuple is not distinct from w.tuple
  and r.classid is not distinct from w.classid
  and r.objid is not distinct from w.objid
  and r.objsubid is not distinct from w.objsubid
  and r.transactionid is not distinct from w.transactionid
  and r.pid <> w.pid
 ),
tmp0 as (
 select *
 from tmp_lock tl
 union all
 select t1.parentid,0::int4
 from tmp_lock t1
 where 1=1
 and t1.parentid not in (select id from tmp_lock)
 ),
tmp3 (pathid,depth,id,parentid) as (
 SELECT array[id]::text[] as pathid,1 as depth,id,parentid
 FROM tmp0
 where 1=1 and parentid=0
 union
 SELECT t0.pathid||array[t1.id]::text[] as pathid,t0.depth+1 as depth,t1.id,t1.parentid
 FROM tmp0 t1, tmp3 t0
 where 1=1 and t1.parentid=t0.id
)
select distinct
 '/'||array_to_string(a0.pathid,'/') as pathid,
 a0.depth,
 a0.id,a0.parentid,lpad(a0.id::text, 2*a0.depth-1+length(a0.id::text),' ') as tree_id,
 --'select pg_cancel_backend('||a0.id|| ');' as cancel_pid,
 --'select pg_terminate_backend('||a0.id|| ');' as term_pid,
 case when a0.depth =1 then 'select pg_terminate_backend('|| a0.id || ');' else null end  as term_pid,
 case when a0.depth =1 then 'select cancel_backend('|| a0.id || ');' else null end  as cancel_pid
 ,a2.datname,a2.usename,a2.application_name,a2.client_addr,a2.wait_event_type,a2.wait_event,a2.state
 --,a2.backend_start,a2.xact_start,a2.query_start
from tmp3 a0
left outer join (select distinct '/'||id||'/' as prefix_id,id
 from tmp0
 where 1=1 ) a1
on position( a1.prefix_id in '/'||array_to_string(a0.pathid,'/')||'/' ) >0
left outer join pg_stat_activity a2 -- select * from pg_stat_activity
on a0.id = a2.pid
order by '/'||array_to_string(a0.pathid,'/'),a0.depth;
```

输出结果格式如下：![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXscr3gJp6Fviazqib4q5JgF5upCltAXz0iaicc8VdGcspMUtujehM0gRoQnQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 附录三：查询当前执行时间超过60s的sql

```
select
 pg_stat_activity.datname,
 pg_stat_activity.pid,
 pg_stat_activity.query,
 pg_stat_activity.client_addr,
 clock_timestamp() - pg_stat_activity.query_start
from
 pg_stat_activity pg_stat_activity
where
 (pg_stat_activity.state = any (array['active'::text,
 'idle in transaction'::text]))
 and (clock_timestamp() - pg_stat_activity.query_start) > '00:00:60'::interval
order by
 (clock_timestamp() - pg_stat_activity.query_start) desc;
```

输出结果格式如下：![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXssSnVDaSiaRYAWica5eYC6icydcPPGne2cd70cb0XuW6icC5eiaJp0UtSKYw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 附录四：查询所有已经获取锁的SQL

```
SELECT pid, state, usename, query, query_start 
from pg_stat_activity 
where pid in (
  select pid from pg_locks l  join pg_class t on l.relation = t.oid 
  and t.relkind = 'r' 
);
```

输出结果格式如下：![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPq4KRwBPkSsBl4NggrGgXXsuiaX5TFcFsbKEn5sETDGs8RBiaKicgPLc8XnoEAP65kH8lvPxlOQAw6kQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

## MySQL与PostgreSQL之间的对比

postgresql数据库锁的分类详细，他不会出现锁升级的情况，但也带来用法的繁琐。

mysql数据库当行锁不是所在主键上时会升级成表锁。

#### mysql和postgresql总体不同基本对比如下：

###### PostgreSQL的优势

- PGSQL没有CPU核心数限制，MySQL能用128核CPU。
- PG主表采用堆表存放，MySQL采用索引组织表，能够支持比MySQL更大的数据量。
- PG的主备复制属于物理复制(完胜逻辑复制，维护简单)，相对于MySQL基于binlog的逻辑复制（`sql_log_bin`、`binlog_format`等参数设置不正确都会导致主从不一致），数据的一致性更加可靠，复制性能更高，对主机性能的影响也更小。
- MySQL的存储引擎插件化机制，存在锁机制复杂影响并发的问题，而PG不存在这个机制。
- PGSQL支持 JIT 执行计划即时编译，使用LLVM编译器，MySQL不支持执行计划即时编译。
- PGSQL一共有255个参数，用到的大概是80个，参数比较稳定，用上个大版本配置文件也可以启动当前大版本数据库(版本兼容性好)，而MySQL一共有707个参数，用到的大概是180个，参数不断增加，就算小版本也会增加参数，大版本之间会有部分参数不兼容情况。参数多引起维护成本加大。比如：PGSQL系统自动设置从库默认只读，不需要人工添加配置，维护简单，MySQL从库需要手动设置参数`super_read_only=on`，让从库设置为只读。

###### MySQL的优势

- MySQL数据库查看sql的执行计划更直观易懂。
- MySQL采用索引组织表，这种存储方式非常适合基于主键匹配的查询、删改操作，但是对表结构设计存在约束。
- MySQL的优化器较简单，系统表、运算符、数据类型的实现都很精简，非常适合简单的查询操作。
- MySQL分区表的实现要优于PG的基于继承表的分区实现，主要体现在分区个数达到上千上万后的处理性能差异较大。



## 二、执行计划

了解 PostgreSQL 执行计划对于程序员来说是一项关键技能，执行计划是我们优化查询，验证我们的优化查询是否确实按照我们期望的方式运行的重要方式。

### PostgreSQL 数据库中的查询生命周期

每个查询都会经历不同的阶段，了解每个阶段对数据库的意义很重要。

- 第一阶段是通过Postgres 的客户端连接到数据库。
- 第二阶段是将查询转换为称为解析树的中间格式。
- 第三阶段就是我们所说的重写系统/规则系统。它采用从第二阶段生成的解析树，并以规划器/优化器可以开始在其中工作的方式重新编写它。
- 第四阶段是最重要的阶段。如果没有规划器，执行器将在如何执行查询、使用什么索引、是否扫描较小的表以消除更多不必要的行等问题上一头雾水。
- 第五个也是最后一个阶段是执行器，它实际执行并返回结果。

PostgreSQL 为每个收到查询产生一个查询计划。 选择正确的计划来匹配查询结构和数据的属性对于好的性能来说绝对是最关键的，因此系统包含了一个复杂的规划器来尝试选择好的计划。 你可以使用EXPLAIN命令察看规划器为任何查询生成的查询计划。



### 执行计划常用命令

```
EXPLAIN [ ( option [, ...] ) ] statement
EXPLAIN [ ANALYZE ] [ VERBOSE ] statement

这里 option可以是：
    ANALYZE [ boolean ]
    VERBOSE [ boolean ]
    COSTS [ boolean ]
    BUFFERS [ boolean ]
    TIMING [ boolean ]
    SUMMARY [ boolean ]
    FORMAT { TEXT | XML | JSON | YAML }
```

#### 参数解读

- ANALYZE，执行命令并且显示实际的运行时间和其他统计信息。这个参数默认被设置为FALSE。
- VERBOSE，显示关于计划的额外信息。特别是：计划树中每个结点的输出列列表、模式限定的表和函数名、总是把表达式中的变量标上它们的范围表别名，以及总是打印统计信息被显示的每个触发器的名称。这个参数默认被设置为FALSE。
- COSTS，包括每一个计划结点的估计启动和总代价，以及估计的行数和每行的宽度。这个参数默认被设置为TRUE。
- BUFFERS，包括缓冲区使用的信息。特别是：共享块命中、读取、标记为脏和写入的次数、本地块命中、读取、标记为脏和写入的次数、以及临时块读取和写入的次数。只有当ANALYZE也被启用时，这个参数才能使用。它的默认被设置为FALSE。
- TIMING，在输出中包括实际启动时间以及在每个结点中花掉的时间。只有当ANALYZE也被启用时，这个参数才能使用。它的默认被设置为TRUE。
- SUMMARY，在查询计划之后包含摘要信息（例如，总计的时间信息）。当使用ANALYZE 时默认包含摘要信息，但默认情况下不包含摘要信息，但可以使用此选项启用摘要信息。 使用EXPLAIN EXECUTE中的计划时间包括从缓存中获取计划所需的时间 以及重新计划所需的时间（如有必要）。
- FORMAT，指定输出格式，可以是 TEXT、XML、JSON 或者 YAML。非文本输出包含和文本输出格式相同的信息，但是更容易被程序解析。这个参数默认被设置为TEXT。
- statement，你想查看其执行计划的任何SELECT、INSERT、UPDATE、DELETE、VALUES、EXECUTE、DECLARE、CREATE TABLE AS或者CREATE MATERIALIZED VIEW AS语句。

#### 常用组合

- 一般查询

```
--在不需要真正执行sql时，需把analyze去掉
explain analyze select … ;
```

- 查询缓存及详细信息

```
--在不需要真正执行sql时，需把analyze去掉
explain (analyze,verbose,buffers) select … ;
```



### 执行计划解读

#### 关键字

首先我们看下执行计划常见的关键字

```
db_test=# explain (analyze,verbose,buffers) select * from db_test.t_test;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Seq Scan on db_test.t_test(cost=0.00..22.32 rows=1032 width=56) (actual time=0.060..1.167 rows=1032 loops=1)
   Output: c_bh, n_dm, c_ah
   Buffers: shared read=12
 Planning Time: 0.283 ms
 Execution Time: 1.730 ms
```

关键字解读

```
cost=0.00..22.32，#0.00代表启动成本，22.32代表返回所有数据的成本。
rows=1032：#表示返回多少行。
width=56，#表示每行平均宽度。
actual time=0.060..1.167，#实际花费的时间。
loops=1，#循环的次数
Output，#输出的字段名
Buffers，#缓冲命中数
shared read，#代表数据来自disk(磁盘)而并非cache(缓存)，当再次执行sql，会发现变成shared hit，说明数据已经在cache中
Planning Time，#生成执行计划的时间
Execution Time，#执行执行计划的时间
```

### 常见扫描方式

PostgreSQL中数据扫描方式很多，常见有如下几种

#### Seq Scan

全表顺序扫描

```
db_test=# explain (analyze,verbose,buffers) select * from db_test.t_ms_aj;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Seq Scan on db_test.t_ms_aj  (cost=0.00..22.32 rows=1032 width=56) (actual time=0.060..1.167 rows=1032 loops=1)
   Output: c_bh, n_dm, c_ah
   Buffers: shared hit=12
 Planning Time: 0.283 ms
 Execution Time: 1.730 ms
```

#### Index Only Scan

按索引顺序扫描，通过VM减少回表，绝大数情况下不需要回表。

```
db_test=# explain (analyze,verbose,buffers) select c_bh from db_test.t_ms_aj where c_bh='db22f5a4f828d0f4eaa0b70679a4d637';
                                                             QUERY PLAN                                                             
------------------------------------------------------------------------------------------------------------------------------------
 Index Only Scan using t_ms_aj_pkey on db_test.t_ms_aj  (cost=0.28..8.29 rows=1 width=33) (actual time=0.079..0.081 rows=1 loops=1)
   Output: c_bh
   Index Cond: (t_ms_aj.c_bh = 'db22f5a4f828d0f4eaa0b70679a4d637'::bpchar)
   Heap Fetches: 1
   Buffers: shared hit=3
 Planning Time: 0.139 ms
 Execution Time: 0.166 ms
```

#### Index Scan

按索引顺序扫描，并回表。

```
db_test=# explain (analyze,buffers) select * from db_test.t_ms_aj where c_bh='db22f5a4f828d0f4eaa0b70679a4d637';
                                                      QUERY PLAN                                                       
-----------------------------------------------------------------------------------------------------------------------
 Index Scan using t_ms_aj_pkey on t_ms_aj  (cost=0.28..8.29 rows=1 width=56) (actual time=0.890..0.894 rows=1 loops=1)
   Index Cond: (c_bh = 'db22f5a4f828d0f4eaa0b70679a4d637'::bpchar)
   Buffers: shared hit=3
 Planning Time: 0.376 ms
 Execution Time: 1.136 ms
```

#### Bitmap Index Scan+Bitmap Heap Scan

按索引取得的BLOCKID排序，然后根据BLOCKID顺序回表扫描，然后再根据条件过滤掉不符合条件的记录。

这种扫描方法，主要解决了离散数据(索引字段的逻辑顺序与记录的实际存储顺序非常离散的情况)，需要大量离散回表扫描的情况。

```
db_test=# explain (analyze,verbose,buffers) select * from db_test.t_ms_aj_bak where n_dm=12;
                            QUERY PLAN                                                             
------------------------------------------------------------------
 Bitmap Heap Scan on db_test.t_ms_aj_bak  (cost=100.85..1303.26 rows=5233 width=56) (actual time=1.477..107.896 rows=5204 loops=1)
   Output: c_bh, n_dm, c_ah
   Recheck Cond: (t_ms_aj_bak.n_dm = 12)
   Heap Blocks: exact=1125
   Buffers: shared hit=1126 read=15
   ->  Bitmap Index Scan on i_ms_aj_bak_n_dm  (cost=0.00..99.54 rows=5233 width=0) (actual time=1.260..1.260 rows=5204 loops=1)
         Index Cond: (t_ms_aj_bak.n_dm = 12)
         Buffers: shared hit=1 read=15
 Planning Time: 0.114 ms
 Execution Time: 109.361 ms
```

#### Hash Join

哈希JOIN，较小的数据集来构建HASH表，然后用较大的数据集去做探测。

```
db_test=# explain (analyze,verbose,buffers) select aj.c_bh from db_test.t_ms_aj aj join db_test.t_ms_dsr dsr on dsr.c_bh_aj=aj.c_bh;
                                                             QUERY PLAN                                                             
------------------------------------------------------------------------------------------------------------------------------------
 Hash Join  (cost=35.22..5378.59 rows=2307 width=33) (actual time=3.121..1254.234 rows=2074 loops=1)
   Output: aj.c_bh
   Inner Unique: true
   Hash Cond: (dsr.c_bh_aj = aj.c_bh)
   Buffers: shared hit=2828
   ->  Seq Scan on db_test.t_ms_dsr dsr  (cost=0.00..4817.86 rows=200186 width=33) (actual time=0.013..598.660 rows=200186 loops=1)
         Output: dsr.c_bh, dsr.c_bh_aj, dsr.c_name
         Buffers: shared hit=2816
   ->  Hash  (cost=22.32..22.32 rows=1032 width=33) (actual time=3.089..3.089 rows=1032 loops=1)
         Output: aj.c_bh
         Buckets: 2048  Batches: 1  Memory Usage: 82kB
         Buffers: shared hit=12
         ->  Seq Scan on db_test.t_ms_aj aj  (cost=0.00..22.32 rows=1032 width=33) (actual time=0.010..1.860 rows=1032 loops=1)
               Output: aj.c_bh
               Buffers: shared hit=12
 Planning Time: 0.396 ms
 Execution Time: 1257.348 ms
```

#### Nested Loop

嵌套循环。其中一个表扫描一次，另一个表则循环多次。

```
db_test=# explain analyze select aj.c_bh from db_test.t_ms_aj aj join db_test.t_ms_dsr dsr on dsr.c_bh_aj=aj.c_bh where aj.n_dm=20;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=8.87..263.50 rows=45 width=33) (actual time=0.058..0.405 rows=37 loops=1)
   ->  Bitmap Heap Scan on t_ms_aj aj  (cost=4.43..17.09 rows=20 width=33) (actual time=0.028..0.067 rows=20 loops=1)
         Recheck Cond: (n_dm = 20)
         Heap Blocks: exact=10
         ->  Bitmap Index Scan on i_ms_aj_n_dm  (cost=0.00..4.43 rows=20 width=0) (actual time=0.018..0.019 rows=20 loops=1)
               Index Cond: (n_dm = 20)
   ->  Bitmap Heap Scan on t_ms_dsr dsr  (cost=4.44..12.30 rows=2 width=33) (actual time=0.014..0.015 rows=2 loops=20)
         Recheck Cond: (c_bh_aj = aj.c_bh)
         Heap Blocks: exact=20
         ->  Bitmap Index Scan on i_ms_dsr_c_bh  (cost=0.00..4.43 rows=2 width=0) (actual time=0.011..0.011 rows=2 loops=20)
               Index Cond: (c_bh_aj = aj.c_bh)
 Planning Time: 0.409 ms
 Execution Time: 0.555 ms
```

#### Merge Join

Merge Join，需要两个JOIN的表的KEY都是先排好顺序的，如果有索引没有排序过程。Merge Join两个表都只扫描一次。

```
db_test=# explain analyze select aj.c_bh from db_test.t_ms_aj aj join db_test.t_ms_dsr dsr on dsr.c_bh=aj.c_ah;
                                                                   QUERY PLAN                                                                    
-------------------------------------------------------------------------------------------------------------------------------------------------
 Gather  (cost=14985.80..15689.01 rows=1032 width=33) (actual time=944.856..951.963 rows=0 loops=1)
   Workers Planned: 1
   Workers Launched: 1
   ->  Merge Join  (cost=13985.80..14585.81 rows=607 width=33) (actual time=851.573..851.573 rows=0 loops=2)
         Merge Cond: (dsr.c_bh = (aj.c_ah)::bpchar)
         ->  Sort  (cost=13911.82..14206.21 rows=117756 width=33) (actual time=747.508..792.472 rows=100093 loops=2)
               Sort Key: dsr.c_bh
               Sort Method: quicksort  Memory: 11282kB
               Worker 0:  Sort Method: quicksort  Memory: 10503kB
               ->  Parallel Seq Scan on t_ms_dsr dsr  (cost=0.00..3993.56 rows=117756 width=33) (actual time=0.035..115.401 rows=100093 loops=2)
         ->  Sort  (cost=73.98..76.56 rows=1032 width=52) (actual time=2.963..3.154 rows=338 loops=2)
               Sort Key: aj.c_ah USING <
               Sort Method: quicksort  Memory: 194kB
               Worker 0:  Sort Method: quicksort  Memory: 194kB
               ->  Seq Scan on t_ms_aj aj  (cost=0.00..22.32 rows=1032 width=52) (actual time=0.082..0.545 rows=1032 loops=2)
 Planning Time: 0.481 ms
 Execution Time: 952.152 ms
```



### 实例

我们先看sql，根据现场反馈修改其他c_dbbh后，sql执行较快，唯独这一个c_dbbh需要一分钟才会出结果。

```
SELECT COUNT(1) 
FROM db_test.t_zh_axx aj
 LEFT JOIN (SELECT n_ccsl,c_ajbh,c_zblx,c_laay FROM db_test.t_zh_zjxx A 
  WHERE
c_bh = (SELECT c_bh FROM db_test.t_zh_zjxx b WHERE b.c_ajbh = A.c_ajbh AND b.c_zblx = '0050002' ORDER BY dt_cjsj DESC NULLS LAST LIMIT 1) 
) zb ON zb.c_ajbh = aj.c_ajbh 
WHERE
 c_dbbh = '0191H4325678D8172F58EE383720D0A9' 
 AND zb.c_zblx = '0050002' 
 AND aj.c_zy = '1628'
--涉及表的数据量
--db_test.t_zh_axx  1200万+
--db_test.t_zh_zjxx  1900万+
```

有经验的同学第一眼看到sql是可能就会发现sql编写有些问题，这里暂时先不管。先看执行计划为什么慢，在进行sql优化。

```
Aggregate  (cost=3214.11..3214.12 rows=1 width=8) (actual time=61097.734..61097.734 rows=1 loops=1)
  ->  Nested Loop  (cost=743.92..3214.11 rows=1 width=0) (actual time=8.702..61097.110 rows=1461 loops=1)
        ->  Bitmap Heap Scan on t_zh_axx aj  (cost=743.36..763.39 rows=5 width=17) (actual time=8.585..11.327 rows=1461 loops=1)
            Recheck Cond:((c_dbbh = '0191H4325678D8172F58EE383720D0A9'::bpchar) AND ((c_zy)::text = '1801'::text))
   Heap Blocks:exact=720
            -> BitmapAnd (cost=743.36..743.36 rows=5 width=0)(actual time=8.479..8.479 rows=0 loops=1)
      -> Bitmap Index Scan on i_t_zh_axx_c_dbbh_c_cbfy (cost=0.00..70.63 rows=1343 width=0)(actual time=0.766..0.766 rows=0 loops=1)
      Index Cond:(c_dbbh = '0191H4325678D8172F58EE383720D0A9'::bpchar)
      -> Bitmap Index Scan on i_t_zh_axx_zblx_c_zy (cost=0.00..672.47 rows=36272 width=0)(actual time=7.644..7.644 rows=0 loops=1)
      Index Cond:((c_zy)::text = '1628'::text)
        ->  Index Scan using i_t_zh_zjxx_c_ajbh on t_zh_zjxx a  (cost=0.56..190.13 rows=1 width=16) (actual time=20.069..41.822 rows=1 loops=1461)
              Index Cond: ((c_ajbh)::text = (aj.c_ajbh)::text)
              Filter: (((c_zblx)::text = '0020002'::text) AND (c_bh = (SubPlan 1)))
              Rows Removed by Filter: 167
              SubPlan 1
                ->  Limit  (cost=44.55..44.56 rows=1 width=41) (actual time=0.247..0.248 rows=1 loops=245603)
                      ->  Sort  (cost=44.55..44.56 rows=1 width=41) (actual time=0.247..0.247 rows=1 loops=245603)
                            Sort Key: b.dt_cjsj DESC NULLS LAST
                            Sort Method: top-N heapsort  Memory: 25kB
                            ->  Index Scan using i_t_zh_zjxx_c_ajbh on t_zh_zjxx b  (cost=0.56..54.82 rows=1 width=41) (actual time=0.017..0.071 rows=38 loops=245603)
                                  Index Cond: ((c_ajbh)::text = (a.c_ajbh)::text)
                                  Filter: ((c_zblx)::text = '0020002'::text)
                                  Rows Removed by Filter: 114
Planning Time: 1.267 ms
Execution Time: 61097.876 ms
```

仔细观察执行计划后发现，占用时间最多的在第2行Nested Loop（actual time=8.702…61097.110），嵌套循环占用了一分钟，然后在16 -> 20行看到（loops=245603），循环了24.5万次。

嵌套循环：其中一个表扫描一次，另一个表则循环多次。这里基本可以确定问题了，找开发确认发现是确实是数据问题，原因是重复上报导致。

#### 改写1

处理掉垃圾数据后，再来看下原sql是否有优化空间，进行sql改写（以下测试数据采用公司测试环境）。

```
--在测试环境原sql执行需要2s，勉强符合公司标准
db_zxzh_jy=# SELECT count(1) from db_test.t_zh_axx aj left join (select n_ccsl,c_ajbh,c_zblx,c_laay from db_test.t_zh_zjxx a where c_bh = (SELECT c_bh
from db_test.t_zh_zjxx b where b.c_ajbh=a.c_ajbh and b.c_zblx = '0020002' order by dt_cjsj desc NULLS LAST LIMIT 1) ) zb on zb.c_ajbh = aj.c_ajbh where c_dbbh = '8B7D8C93864E0D0C3E3259C49ED65471' and zb.c_zblx = '0020002' and aj.c_zy = '1801';
 count 
-------
  1356
(1 行记录)
Time: 2227.680 ms (00:02.228)
```

原sql中left join是一个自关联，取相同c_ajbh中dt_cjsj时间最大的一条与t_zh_axx进行关联。

```
--在第一次修改过程中陷入原sql的固定模式，想把自连接改掉，直接取相同c_ajbh中时间最大的一条
explain analyze
select count(*) 
from db_test.t_zh_axx aj
join (select c_ajbh,c_zblx,max(dt_cjsj) from db_test.t_zh_zjxx group by c_ajbh,c_zblx) zbajxx on zbajxx.c_ajbh = aj.c_ajbh
where aj.c_dbbh = '8B7D8C93864E0D0C3E3259C49ED65471' 
and aj.c_zy = '1801'
and zbajxx.c_zblx = '0020002'

--改完发现更慢，根据执行计划进行解读
--执行计划选择的是Merge Join，这种join方式是需要两个表关联字段事先排序
--可以看到两个表的Sort Key是c_ajbh，t_zh_zjxx表没用到索引，先进性全表扫描，然后进行排序，然后是Merge Join

QUERY PLAN 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1046565.51..1046565.52 rows=1 width=8) (actual time=24074.583..24074.583 rows=1 loops=1)
   ->  Merge Join  (cost=1012316.07..1046565.50 rows=6 width=0) (actual time=24057.923..24074.497 rows=1356 loops=1)
         Merge Cond: ((t_zh_zjxx.c_ajbh)::text = (aj.c_ajbh)::text)
         ->  GroupAggregate  (cost=1007105.01..1028294.00 rows=1044828 width=30) (actual time=23062.977..24014.438 rows=176529 loops=1)
               Group Key: t_zh_zjxx.c_ajbh, t_zh_zjxx.c_zblx
               ->  Sort  (cost=1007105.01..1010685.25 rows=1432095 width=22) (actual time=23062.958..23895.947 rows=347291 loops=1)
                     Sort Key: t_zh_zjxx.c_ajbh
                     Sort Method: external merge  Disk: 45504kB
                     ->  Seq Scan on t_zh_zjxx  (cost=0.00..831303.47 rows=1432095 width=22) (actual time=0.031..9310.987 rows=1366950 loops=1)
                           Filter: ((c_zblx)::text = '0020002'::text)
                           Rows Removed by Filter: 18389119
         ->  Sort  (cost=5211.06..5211.07 rows=6 width=17) (actual time=4.402..4.524 rows=1461 loops=1)
               Sort Key: aj.c_ajbh
               Sort Method: quicksort  Memory: 117kB
               ->  Index Scan using t_zh_axx_c_dbbh_idx on t_zh_axx aj  (cost=0.56..5210.98 rows=6 width=17) (actual time=0.099..1.896 rows=1461 loops=1)
                     Index Cond: (c_dbbh = '8B7D8C93864E0D0C3E3259C49ED65471'::bpchar)
                     Filter: ((c_zy)::text = '1801'::text)
 Planning Time: 1.547 ms
 Execution Time: 24082.631 ms
```

#### 改写2

我们改变下思路，再看下原sql想要得到什么结果。SQL中只有c_zblx = '0020002’这一个条件，随机选一条即可，并不必须是dt_cjsj创建时间最大的一条。

```
--用exists改写
explain analyze 
select count(*) from db_test.t_zh_axx aj
where exists (select 1 from db_test.t_zh_zjxx zbajxx where zbajxx.c_ajbh=aj.c_ajbh and c_zblx = '0020002')
and aj.c_dbbh = '8B7D8C93864E0D0C3E3259C49ED65471' 
AND aj.c_zy = '1801' 

--执行计划都走索引
--值得关注的是join的方式是Nested Loop Semi Join，多了个Semi。Semi Join支持支持hash, merge, nestloop几种JOIN方法
--semi Join的操作在EXISTS中有一个返回TRUE的操作即可，所以在有索引的情况下很大概率下并不需要全表扫描

QUERY PLAN 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
Aggregate  (cost=5560.83..5560.84 rows=1 width=8) (actual time=38.158..38.158 rows=1 loops=1)
  ->  Nested Loop Semi Join，  (cost=1.12..5560.82 rows=6 width=0) (actual time=0.072..37.912 rows=1356 loops=1)
        ->  Index Scan using t_zh_axx_c_dbbh_idx on t_zh_axx aj  (cost=0.56..5210.98 rows=6 width=17) (actual time=0.042..1.315 rows=1461 loops=1)
              Index Cond: (c_dbbh = '8B7D8C93864E0D0C3E3259C49ED65471'::bpchar)
              Filter: ((c_zy)::text = '1801'::text)
        ->  Index Scan using i_t_zh_zjxx_c_ajbh on t_zh_zjxx zbajxx  (cost=0.56..58.50 rows=1 width=16) (actual time=0.024..0.024 rows=1 loops=1461)
              Index Cond: ((c_ajbh)::text = (aj.c_ajbh)::text)
              Filter: ((c_zblx)::text = '0020002'::text)
Planning Time: 0.852 ms
Execution Time: 38.255 ms
```

优化后速度大大提升，验证多个编号结果也无问题。

### 小结

通过看执行计划我们能得到很多有用的信息，根据这些信息找到相应的应对策略。



## 三、分区分表

在组件开发迭代的过程中，随着使用时间的增加，数据库中的数据量也不断增加，因此数据库查询越来越慢。

通常加速数据库的方法很多，如添加特定的索引，将日志目录换到单独的磁盘分区，调整数据库引擎的参数等。这些方法都能将数据库的查询性能提高到一定程度。

对于许多应用数据库来说，许多数据是历史数据并且随着时间的推移它们的重要性逐渐降低。如果能找到一个办法将这些可能不太重要的数据隐藏，数据库查询速度将会大幅提高。可以通过DELETE来达到此目的，但同时这些数据就永远不可用了。

分区表是关系型数据库提供的一个亮点特性，比如Oracle对分区表的支持已经非常成熟，广泛使用于生产系统，PostgreSQL也支持分区表，只是道路有些曲折，早在10版本之前PostgreSQL分区表一般通过继承加触发器方式实现，这种分区方式不能算是内置分区表，而且步骤非常烦琐，PostgreSQL10版本一个重量级的新特性是支持内置分区表，在分区表方面前进了一大步，目前支持范围分区和列表分区。


### 表分区

表分区是指在逻辑上将一个大表拆分为较小的物理部分。分区可以带来几个好处：

- 在某些情况下，查询性能可以显著提高，尤其是当表的大多数大量访问的行都放在单个分区或少量分区中时。分区取代了索引的前导列，减小了索引大小，使索引中大量使用的部分更可能适合内存。
- 当查询或更新访问单个分区的很大一部分时，可以通过利用该分区的顺序扫描来提高性能，而不是使用分散在整个表中的索引和随机访问读取。
- 如果分区设计中计划了分区，则可以通过添加或删除分区来完成批量加载和删除。使用执行或删除单个分区比批量操作快得多。
- 很少使用的数据可以迁移到更便宜、更慢的存储介质。

只有当一个表会很大时，这些好处通常才是值得的。表将从分区中受益的确切点取决于应用程序，尽管经验法则是表的大小应超过数据库服务器的物理内存。

#### 什么时候考虑使用表分区Partition？

- 一张表的查询速度已经慢到影响使用的时候。
- sql经过优化
- 数据量大
- 表中的数据是可以分段的
- 对数据的操作往往只涉及一部分数据，而不是所有的数据

随着使用时间的增加，数据库中的数据量也不断增加，因此数据库查询越来越慢。

加速数据库的方法很多，如添加特定的索引，将日志目录换到单独的磁盘分区，调整数据库引擎的参数等。这些方法都能将数据库的查询性能提高到一定程度。

对于许多应用数据库来说，许多数据是历史数据并且随着时间的推移它们的重要性逐渐降低。如果能找到一个办法将这些可能不太重要的数据隐藏，数据库查询速度将会大幅提高。可以通过DELETE来达到此目的，但同时这些数据就永远不可用了。

因此，需要一个高效的把历史数据从当前查询中隐藏起来并且不造成数据丢失的方法。PostgreQL 的数据库表分区即能达到此效果。

### PostgreSQL 11 内置分区分表

#### PostgreSQL 中的分区支持

PostgreSQL从10.0版本开始，开始引入内置分区机制partition。

Partition数据库表分区把一个大的物理表分成若干个小的物理表，并使得这些小物理表在逻辑上可以被当成一张表来使用。

- **主表/父表/Master Table**　该表是创建子表的模板。它是一个正常的普通表，但通常情况下它应该并不储存任何数据，而是将所有记录重定向到子表中进行存储。
- **子表/分区表/Child Table/Partition Table**　这些表继承并属于一个主表。子表中存储所有的数据。主表与分区表属于一对多的关系，也就是说，一个主表包含多个分区表，而一个分区表只从属于一个主表

#### 数据库表分区的优势

- 在特定场景下，查询性能可以极大提高，尤其是当大部分经常访问的数据记录在一个或少数几个分区表上时。表分区减小了索引的大小，并使得常访问的分区表的索引更容易保存于内存中。
- 当查询或者更新访问一个或少数几个分区表中的大部分数据时，可以通过顺序扫描该分区表而非使用大表索引来提高性能。
- 可通过添加或移除分区表来高效的批量增删数据。如可使用**ALTER TABLE NO INHERIT**可将特定分区从主逻辑表中移除（该表依然存在，并可单独使用，只是与主表不再有继承关系并无法再通过主表访问该分区表），或使用**DROP TABLE**直接将该分区表删除。这两种方式完全避免了使用**DELETE**时所需的**VACUUM**额外代价。
- 很少使用的数据可被迁移到便宜些的慢些的存储介质中

以上优势只有当表非常大的时候才能体现出来。一般来说，当表的大小超过数据库服务器的物理内存时以上优势才能体现出来。

#### PostgreSQL 11 的新特性

PostgreSQL从10版本支持通过表继承来实现表的分区。父表是普通表并且正常情况下并不存储任何数据，它的存在只是为了代表整个数据集。

从11版本开始PostgreSQL可实现如下3种表分区。

- **范围分区**　每个分区表包含一个或多个字段组合的一部分，并且每个分区表的范围互不重叠。比如可近日期范围分区
- **列表分区**　分区表显示列出其所包含的列值
- **哈希分区** PostgreSQL11版本引入，可以根据自定义的hash规则，通过为每个分区指定模数和余数来对表进行分区。每个分区将保存分区键的哈希值除以指定的模数将生成指定余数的行。

如果项目组件的数据表需要使用上面未列出的表分区形式，可以使用替代方法（如基于10版本的继承和视图）。这些方法通常更具有灵活性，但可能部分特性没有内置的分区优化，所幸的是，目前PostgreSQL 11 版本已经对此做了大量优化。

### PostgreSQL 内置分区表使用

PostgreSQL 10 一个重量级新特性是支持内置分区表，用户不需要预先在父表上定义INSERT、DELETE、UPDATE 触发器，对父表的DML操作会自动路由到相应分区，相比传统分区表大幅度降低了维护成本，目前仅支持范围分区和列表分区，本小节将以创建范围分区表为例，演示 PostgreSQL 10 内置分区表的创建、使用与性能测试。

#### 创建分区表

创建分区表的主要语法包含两部分:创建主表和创建分区。创建主表语法如下:

```
CREATE TABLE table_name ( ... )
  { PARTITION BY { RANGE | LIST } ( { column_name | ( expression ) }
```

创建主表时须指定分区方式，可选的分区方式为RANGE范围分区或LIST列表分区,并指定字段或表达式作为分区键。
创建分区的语法如下:

```
CREATE TABLE table_name
PARTITION OF parent_table [ (
) ] FOR VALUES partition_bound_spec
```

创建分区时必须指定是哪张表的分区，同时指定分区策略partition_bound_spec，如果是范围分区，partition_bound_spec须指定每个分区分区键的取值范围，如果是列表分区partition_bound_spec，需指定每个分区的分区键值。

PostgreSQL10创建内置分区表主要分为以下几个步骤：

- 创建父表，指定分区键和分区策略。
- 创建分区，创建分区时须指定分区表的父表和分区键的取值范围，注意分区键的范围不要有重叠，否则会报错。
- 在分区上创建相应索引，通常情况下分区键上的索引是必须的，非分区键的索引可根据实际应用场景选择是否创建。

#### 内置分区表注意事项

使用内置分区表有以下注意事项:

- 1.当往父表上插入数据时，数据会自动根据分区键路由规则插入到分区中，目前仅支持范围分区和列表分区。
- 2.分区表上的索引、约束需使用单独的命令创建，目前没有办法一次性自动在所有分区上创建索引、约束。
- 3.内置分区表不支持定义（全局）主键，在分区表的分区上创建主键是可以的。
- 4.内置分区表的内部实现使用了继承。
- 5.如果UPDATE语句的新记录违反当前分区键的约束则会报错，UPDAET语句的新记录目前不支持跨分区的情况。
- 6.性能方面:根据本节的测试场景，内置分区表根据非分区键查询相比普通表性能差距较大，因为这种场景分区表的执行计划会扫描所有分区;根据分区键查询相比普通表性能有小幅降低，而查询分区表子表性能相比普通表略有提升。
- 

### 继承式表分区的使用

PostgreSQL从10版本开始，引入了基于继承的分区机制。

#### 创建主表/父表

不用为该表定义任何检查限制，除非需要将该限制应用到所有的分区表中。同样也无需为该表创建任何索引和唯一限制。这里我们以项目开发中常用到的告警查询为例，创建一张tb_test_alarm表。

```
CREATE TABLE public.tb_test_alarm (
   id varchar(64) NOT NULL,
   alarm_type varchar(10) NOT NULL,
 
   happen_time timestamptz NOT NULL,
 
   create_time timestamptz NULL,
   update_time timestamptz NULL,
    "desc" text NULL,
   device_id varchar(64) NOT NULL,
 
    CONSTRAINT tb_test_pk PRIMARY KEY (id)
);
```

创建的表结构如下图所示![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPqia3ibYPyUc3SBDnZeoP4Oeb6cmP4lUo6PIDOg43V9TI5KogHNHibsQZePEjmSnd9JviaGd6ddP5qmvA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

#### 创建子分区表

每个分区表必须继承自主表，并且正常情况下都不要为这些分区表添加任何新的列。子表尽量保持和父表一致的字段。

此处以每月分区表为例

```
create table tb_test_alarm_2020_12 () inherits (tb_test_alarm);
create table tb_test_alarm_2020_11 () inherits (tb_test_alarm);
create table tb_test_alarm_2020_10 () inherits (tb_test_alarm);
create table tb_test_alarm_2020_09 () inherits (tb_test_alarm);
```

#### 创建分区表路由函数

```
        --创建分区函数
CREATE OR REPLACE FUNCTION alarm_partition_trigger()
RETURNS TRIGGER AS $$
BEGIN
    IF NEW.happen_time >= '2020-09-01 00:00:00' and NEW.happen_time <= '2020-09-30 23:59:59'
    THEN
        INSERT INTO tb_test_alarm_2020_09 VALUES (NEW.*);
    ELSIF NEW.happen_time >= '2020-10-01 00:00:00' and NEW.happen_time <= '2020-10-31 23:59:59'
    THEN
        INSERT INTO tb_test_alarm_2020_10 VALUES (NEW.*);
    ELSIF NEW.happen_time >= '2020-11-01 00:00:00' and NEW.happen_time <= '2020-11-30 23:59:59'
    THEN
        INSERT INTO tb_test_alarm_2020_11 VALUES (NEW.*);
    ELSIF NEW.happen_time >= '2020-12-01 00:00:00' and NEW.happen_time <= '2020-12-31 23:59:59'
    THEN
        INSERT INTO tb_test_alarm_2020_12 VALUES (NEW.*);
    END IF;
    RETURN NULL;
END;
$$
LANGUAGE plpgsql;
--挂载分区Trigger
CREATE TRIGGER insert_almart_partition_trigger
BEFORE INSERT ON tb_test_alarm
FOR EACH ROW EXECUTE PROCEDURE alarm_partition_trigger();
```

插入成功后，可以看到100万条数据成功执行了插入，且由于我们前面编写的分区路由函数生效，数据会根据happen_time自动的插入到子表中。这里数据仍会显示在父表中，但是实际上父表仅仅作为整个分区表结构的展示，实际插入的记录是保存在子表中。如下图所示。![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPqia3ibYPyUc3SBDnZeoP4Oeb77lkicbe4B9LmS830Im0SsIsL0jzSKj7sjNgmVtBAcTO87F5XO7WSMg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)设置分表约束前，查询效率。执行查询语句

```
explain analyze select * from tb_test_alarm tta where happen_time < '2020-12-01 00:00:00'
```

结果如下：![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPqia3ibYPyUc3SBDnZeoP4OebGiaUVP35mkxtu3caWwLolp5lNribpfhhAQrJOM7d5YiaHod54pIfV4pCw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)需要消耗 474.307ms，扫描主表下所有子表来查询。

在执行查询时，PostgreSQL默认将会把查询条件应用到该表结构的所有分区上，因为PosgreSQL不知道这些分区表表名和表内容的关联性。于是需要添加表约束，它会告诉数据库这些表的内容，并允许规划器根据条件去查询对应的子分区，这样在很多情况下，能极大地加快查询速度。

应用分区表约束的语法为ADD CHECK(CONDITION)

```
ALTER TABLE tb_test_alarm_2020_12
ADD CONSTRAINT tb_test_alarm_2020_12_check_time_key
CHECK (happen_time>='2020-12-01 00:00:00' and happen_time <= '2020-12-31 23:59:59');
ALTER TABLE tb_test_alarm_2020_11
ADD CONSTRAINT tb_test_alarm_2020_11_check_time_key
CHECK (happen_time>='2020-11-01 00:00:00' and happen_time <= '2020-11-30 23:59:59');
ALTER TABLE tb_test_alarm_2020_10
ADD CONSTRAINT tb_test_alarm_2020_10_check_time_key
CHECK (happen_time>='2020-10-01 00:00:00' and happen_time <= '2020-10-31 23:59:59');
ALTER TABLE tb_test_alarm_2020_09
ADD CONSTRAINT tb_test_alarm_2020_09_check_time_key
CHECK (happen_time>='2020-09-01 00:00:00' and happen_time <= '2020-09-30 23:59:59');
```

建议对每个分区表增加一个特定的约束，以防止全表查询扫描查询时间过长。

并且在PostgreSQL中，这些表约束是可以重叠的，但一般来说创建非重叠的表约束会更好。重叠的表约束只有在一定特定场景下有意义。

在创建好上述告警信息表及分区表后，我们可以执行一次插入操作和查询，并分析其查询计划来查看分区是否生效以及效果如何。

再次执行查询操作，会发现，sql没有去查询表4的内容，时间也有所缩短。



## 四、事务与并发控制

当多个事务并发执行时, 即使每个单独的事务都正确执行, 数据库的一致性也可能被破坏.。

为了控制 **并发事务** 之间的相互影响, 解决并发可能带来的数据不一致问题, 数据库的并发控制系统 引入了 基于锁的并发控制(Lock-Based Concurrency Control) 和 基于多版本的并发控制机制 MVCC (Mult-Version。

### 事务

**事务** 是数据库系统执行过程中最小的逻辑单位。

当**事务**被提交时, 数据库管理系统 要确保一个事务中的 所有操作都成功完成, 并在数据库中永久保存; 如果一个事务中的一部分没有成功, 则系统会把数据库回滚到操作执行之前的状态。

#### 事务有 4 个特性:

1. **原子性(Atomicity)**: 一个事务的所有操作, 要么全部执行, 要么全部不执行。
2. **一致性(Consistency)**: 保证数据库从一个正确的状态(满足约束)到另一个正确的状态。
3. **隔离性(Isolation)**: 事务并发执行时, 可能会交叉执行, 从而导致不一致的情况发生. 确保事务并发执行时, 每个事务都感觉不到有其他事务在并发的执行。
4. **持久性(Durability)**: 一个事务完成后, 它对数据库的改变应该永久保存在数据库中。

这 4 个特性也称之为 **ACID**.

- **事务一致性** 由主键, 外键这类约束保证。
- **持久性** 由预写日志(WAL) 和数据库管理系统的恢复子系统保证。
- **原子性**和**隔离性** 由 事务管理器 和 MVCC 来控制。

#### 事务并发引发的问题

如果所有的事务都按照顺序执行, 那么执行时间就没有重叠交错, 也就不会有并发问题。

PostgreSQL 把 事务并发 导致的问题 总结为:

- **脏读(Dirty read)**, 事务A 读取了 事务B 已经修改但是还没有提交的数据。
- **不可重复读(Non-repeatable read)**, 事务A 读取了数据X; 然后 事务B 修改了数据X 并提交; 然后事务A 再次读取数据X. 对于事务A来说, 两次读取结果不一致. 这种现象就是 不可重复读。
- **幻读(Phantom read)**, 一个事务的两次执行相同的查询, 结果集数目不一致. 幻读 可以 认为是 受 `INSERT` 和 `DELETE` 影响 不可重复读 的特例。
- **序列化异常(Serialization anomaly)**, 在可重复读情况下, 可能会出现序列化异常. 比如 `X=1` 事务A 执行 `X++` 操作; 在事务A 提交之前, 事务B 修改 `X=10` 并提交成功; 由于事务A 是可重复读的, 事务A 看到的数据还是 `X=1`. 这就发生了序列化异常: 先执行事务A 和 先执行事务B 的结果是不一样的。
- 

#### ANSI SQL 标准的事务隔离级别

为了避免 事务与事务之间 并发执行 引发的副作用, 最简单的方法是 串行地 执行事务, 但是 串行化 会大幅降低系统吞吐量, 降低系统资源利用率。

为此, ANSI(American National Standards Institute, 美国国家标准学会) SQL 标准定义了 4 类事务隔离级别:

- **读未提交(Read Uncommitted)**: 所有事务都可以看到其他未提交事务的执行结果. 可以看到 读未提交 允许 脏读 发生, 脏读是非常危险的, 查询结果非常不可控, 所以 读未提交 事务隔离级别 很少实际应用。
- **读已提交(Read Committed)**: 这是 PostgreSQL 默认的隔离级别, 它满足了 一个事务 只能看到 已提交事务 对关联数据所做的改变。
- **可重复读(Repeatable Read)**: 确保同一个事务在看到的数据内容是一致的。
- **可序列化(Serializable)**: 最高的隔离级别, 通过强制事务排序, 使之不可能相互冲突, 从而解决幻读问题。

下表是 ANSI SQL 标准定义的事务隔离级别与读现象的关系:![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPoU6banwBJpvJp9MYjaOXaqPpicjicJaRZHib9sV4GdI3HjiaxO5QgqW56To7uvGP3QxldKBUbUMpuvfw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)对于同一个事务来说, 不同的事务隔离级别执行结果可能不同。

事务隔离级别越高, 越能保证数据的完整性和一致性, 但增加了阻塞其他事务的概率, 并发性能越差, 吞吐量也越低。

对于大多应用程序, 优先考虑 Read Committed 隔离级别，它可以避免脏读, 而且有较好的并发性能。尽管它会导致不可重复读,幻读问题,这类问题可以由应用程序加锁来控制。

### PostgreSQL 的事务隔离级别

postgresql中的两种隔离级别如下：

#### 读已提交：

读已提交是postgresql里的默认级别。当一个事务运行在这个隔离级别时，一个select查询只能看到查询开始之前已提交的数据，而无法看到未提交的数据或者在查询执行期间其他事务已经提交的数据。

如果两个事务在对同一组数据进行更新操作，那么第二个事务需要等待第一个事务提交或者更新回滚。如果第一个事务进行提交，系统将重新计算查询条件，符合条件后第二个事务继续进行更新操作；如果第一个事务进行更新回滚，那么他的作业将被忽略，第二个事务将继续更新最初发现的行。

#### 可串行化：

可串行化基本提供最严格的事务隔离。这个级别模拟串行的事务执行，就好像事务将一个接着一个地串行（而不是并行）执行。不过，使用这个级别的应用必须准备在串行化失败的时候重新启动事务。

如果两个事务在对同一组数据进行更新操作，那么串行化事务就将等待第一个正在更新的事务提交或回滚。如果第一个事务提交了，那么串行化事务将回滚，从头开始重新进行整个事务；如果第一个事务回滚，那么它的影响将被忽略，这个可串行化的事务就可以在该元祖上进行更新操作。

下面的表格是 PostgreSQL 中不同的事务隔离级别与读现象的关系:![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/tuSaKc6SfPoU6banwBJpvJp9MYjaOXaqaZjOqtlKthia9ibuoVEcWMyExa9ibgGejWFwNSepMKVHicraa2MicMbkjtQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)PostgreSQL 只实现了 3 种 隔离级别。在 PostgreSQL 中, Read Uncommitted 和 Read Committed 是一样的。

#### 查看和设置数据库的事务隔离级别

查看 PostgreSQL 全局事务隔离级别:

```
SELECT name, setting 
FROM pg_settings 
WHERE name = 'default_transaction_isolation';

-- 或者
SELECT  current_setting('transaction_isolation');
```

修改全局的事务隔离级别:

```
ALTER SYSTEM 
SET default_transaction_isolation TO  'REPEATABLE READ';

-- 修改之后 reload 实例使之生效
SELECT pg_reload_conf();
```



### PostgreSQL 事务管理

在postgresql里，一个事务是通过把SQL命令用：begin 和 commit命令包围实现的。事务块是指包围在begin 和 commit之间的语句。

事务控制命令仅用于DML命令INSERT，UPDATE和DELETE。创建表或删除它们时不能使用它们，因为这些操作会在数据库中自动提交。

#### 事务控制命令

###### BEGIN TRANSACTION：开始事务

BEGIN TRANSACTION命令：可以使用BEGIN TRANSACTION或简单的BEGIN命令来开始事务。这样的事务通常会持续下去，直到遇到下一个COMMIT或ROLLBACK命令。但如果数据库关闭或发生错误，则事务也将ROLLBACK。
以下是启动/开始事务的简单语法：

```
BEGIN;
or
BEGIN TRANSACTION;
```

###### COMMIT：保存更改

或者您可以使用END TRANSACTION命令

COMMIT命令是用于将事务调用的更改保存到数据库的事务命令。COMMIT命令自上次的COMMIT或ROLLBACK命令后将所有事务保存到数据库。COMMIT命令的语法如下：

```
COMMIT;
or
END TRANSACTION;
```

###### ROLLBACK：回滚更改

ROLLBACK命令ROLLBACK命令是用于还原尚未保存到数据库的事务的事务命令。自上次发出COMMIT或ROLLBACK命令以来，ROLLBACK命令只能用于撤销事务。ROLLBACK命令的语法如下：

```
ROLLBACK;
```



#### 普通的事务操作

###### 打开/关闭自动提交

在使用psql等一些客户端的工具时，事务的自动提交功能是默认打开的，所以我们每次执行一条SQL语句都会自动提交。在psql中手动的打开自动提交的方法是执行以下命令：

```
postgres=# set AUTOCOMMIT on
postgres-# 
postgres-# set AUTOCOMMIT off
postgres-# 
postgres-# \echo :AUTOCOMMIT 
on
postgres-# 
```

###### 手动开启事务

Postgresql中可以使用BEGIN命令来手动开启事务，手动开启事务之后也就相当于关闭了事务自动提交的功能。

如果我们要手动控制事务，建议使用这种方式:

- 1.使用 BEGIN 可以更见显式的提醒我们当前是在手动事务中，需要手动commit或者rollback；
- 2.\set AUTOCOMMIT off这种方式，只适合在psql中使用，因为AUTOCOMMIT是psql的一个变量。

下面的例子，就是使用BEGIN开启一个事务：

```
postgres=# create table t1(id int,name text);
CREATE TABLE
postgres=# begin;
BEGIN
postgres=*# insert into t1 (id,name) values (1,'李四');
INSERT 0 1
postgres=*# insert into t1 (id,name) values (2,'张三');
INSERT 0 1
postgres=# 
```

此时，还没有提交，我们可以开启另外一个会话查看t1表，发现表中还是空的：

```
postgres=# select * from t1;
 id | name 
----+------
(0 rows)

postgres=#
```

提交的方式有两种，第一种是显示的使用commit命令：

```
postgres=*# commit;
COMMIT
postgres=# 
```

使用这种方式提交并不会关闭当前的事务，要想提交时同时结束事务，需要使用end命令：

```
postgres=# begin;
BEGIN
postgres=*# insert into t1 (id,name) values (3,'麻子');
INSERT 0 1
postgres=*# end;
COMMIT
postgres=# 

# 提交前
postgres=# select * from t1;
 id | name 
----+------
  1 | 李四
  2 | 张三
(2 rows)

# 提交后
postgres=# select * from t1;
 id | name 
----+------
  1 | 李四
  2 | 张三
  3 | 麻子
(3 rows)

postgres=#
```

不管使用哪种方式，提交之后，我们在另外的session中都会查看到t1表中新增的数据。

在手动开启事务时，也可以使用检查点savepoint。

下面的语句，就是在插入第一条数据之后保存了一个检查点，然后继续insert，最后回滚到保存的检查点再进行提交，最终的效果是只有第一条数据插入有效：

```
postgres=# begin;
BEGIN
postgres=*# insert into t1 (id,name) values (4,'李四');
INSERT 0 1
postgres=*# savepoint apoint;
SAVEPOINT
postgres=*# insert into t1 (id,name) values (5,'张三');
INSERT 0 1
postgres=*# rollback to savepoint apoint;
ROLLBACK
postgres=*# end;
COMMIT
postgres=#
```

查询以上语句执行的结果：

```
postgres=# select * from t1;
 id | name 
----+------
  1 | 李四
  2 | 张三
  3 | 麻子
  4 | 李四
(4 rows)

postgres=# 
```

#### DDL事务

DDL事务是Postgresql很有特色的一个功能，其它的关系型数据库很多是不支持DDL事务的。所谓DDL事务就是在执行create table、alter table等这些DDL语句时，支持事务的回滚或提交。

DDL事务创建的方式其实和普通事务一致，都是使用BEGIN命令开启一个事务，也可以设置savepoint，然后进行commit或者rollback。下面的例子就是开启了一个DDL事务，创建了t3、t4然后设置savepiont，再创建t5，最后rollback到保存的检查点并进行提交。最终的效果就是只创建了t3和t4没有创建t5。

```
postgres=# begin;
BEGIN
postgres=*# create table t3(id int);
CREATE TABLE
postgres=*# create table t4(id int);
CREATE TABLE
postgres=*# savepoint bpoint;
SAVEPOINT
postgres=*# create table t5(id int);
CREATE TABLE
postgres=*# rollback to savepoint bpoint;
ROLLBACK
postgres=*# end;
COMMIT
```

我们可以查看创建的结果，以验证符合我们的预期（t1和t2是之前创建好的表）：

```
postgres=# \dt t*
        List of relations
 Schema | Name | Type  |  Owner   
--------+------+-------+----------
 public | t1   | table | postgres
 public | t3   | table | postgres
 public | t4   | table | postgres
(3 rows)
```

#### 分布式事务

目前分布式架构系统的的势头愈演愈烈，在分布式的架构中一个回避不了的问题就是怎么把不同服务或者不同数据块实例间的操作放到同一个事务，也就是支持分布式事务？

目前比较成熟的方案有两阶段提交、三阶段提交、以及一些比较成熟的第三方框架：阿里的seata、txlcn等等。Postgresql为了支持分布式的事务，实现了两阶段提交的事务方式。

所谓的两阶段提交，就是将事务的提交分成了两个过程：

- （1）在执行完成DML语句（update、insert、delete）之后，先进行事务的预提交。预提交的过程不会真的提交数据，但是数据库可以保证只要进行了预提交，数据就不会再丢失，即使数据库发生了重启、宕机。Postgresql中使用PREPARE TRANSACTION命令进行预提交。
- （2）完成了预提交之后，就可以真正的提交事务了，Postgresql中使用COMMIT PREPARED命令进行数据的最终提交。

使用分布式事务修改下postgresql.conf中`max_prepared_transactions`的参数，这个参数默认是0，表示不支持分布式事务;需要改成一个大于0的数字，然后重启数据库。

`max_prepared_transactions`只能通过修改postgresql.conf完成，如果通过set命令修改会报错：

```
postgres=# set max_prepared_transactions=10;
ERROR:  parameter "max_prepared_transactions" cannot be changed without restarting the server
```

例子还是向t1表中插入两条数据，然后用分布式事务的方式进行提交。不过在此之前，

**step 1**.开启事务并执行insert语句：

```
postgres=# begin;
BEGIN
postgres=*# insert into t1 values(1,'tom');
INSERT 0 1
postgres=*# insert into t1 values(2,'jerry');
INSERT 0 1
```

**step 2**.使用PREPARE TRANSACTION进行预提交：

```
postgres=*# PREPARE TRANSACTION 'transaction_001';
PREPARE TRANSACTION
postgres=# 
```

transaction_001是我们为分布式事务定义的一个事务ID，通过这个事务ID可以保证所有的数据库实例的事务属于同一个分布式的事务，它需要保证在全局的共享和唯一。

**step 3**.完成了上述步骤之后，就完成了事务的预提交过程，此时如果我们重启了数据库，预提交的数据也不会丢失。

```
pg_ctl restart
```

**step 4**.使用COMMIT PREPARED进行最终提交：

重启了数据库之后，我们先查看下t1表里面有没有我们插入的数据，以验证预提交阶段是不会实际插入数据的：

```
postgres=# select * from t1;
 id | name 
----+------
  1 | 李四
  2 | 张三
  3 | 麻子
  4 | 李四
(4 rows)

postgres=# c
```

**step 5**.查询的数据为空，接下来再执行最终提交的命令：

```
postgres=# commit prepared 'transaction_001';
COMMIT PREPARED
postgres=#
```

再去查询t1表，发现数据被成功插入进去。

```
postgres=# select * from t1;
 id | name  
----+-------
  1 | 李四
  2 | 张三
  3 | 麻子
  4 | 李四
  1 | tom
  2 | jerry
(6 rows)

postgres=# 
```

### PostgreSQL 的并发控制

为了保证事务的隔离性, 系统必须对 并发事务 之间的相互作用加以控制, 这就是数据库管理系统的 **并发控制器** 要做的事情。

并发控制模型有 **基于锁的并发控制(Lock-Based Concurrency Control)** 和 **基于多版本的并发控制(Multi-Version Concurrency Control)**。

#### 基于锁的并发控制

为了解决并发问题, 数据库引入了 “锁” 的概念。

有两种锁类型: 排它锁(Exclusive locks, X 锁) 和 共享锁(Share locks, S 锁)。

加锁对象的大小称为 锁粒度(granularity)。

加锁的对象可以是 逻辑单元: 属性值, 属性值的集合, 关系, 索引项, 甚至整个数据库。

也可以是物理单元: 页(数据页或索引页), 物理记录等。

#### 基于多版本的并发控制(MVCC)

MVCC通过把数据项的旧值保存在系统中, 来保证并发事务的正确性。

一般把 基于锁的并发控制 称为 悲观机制; 把 MVCC 称为 乐观机制.
这是因为 锁 是一种预防性机制, 写会阻塞读, 读会阻塞写; MVCC 是一种**后验性**机制, 等到提交的时候才检查是否有冲突。

由于 MVCC 读写不会相互阻塞, 避免了大粒度和长时间的锁定, 能更好地适应 对读的响应速度 和 并发性要求高的场景, 常见的数据库如 Oracle, PostgreSQL, MySQL(Innodb) 都使用 MVCC 做 并发控制机制。

在 MVCC 中, 每一个写操作会创建一个新的版本. 当事务发起一个读操作时, 并发控制器选择一个版本读, 连同版本号一起读出, 在更新时对此版本号加一。

PostgreSQL 为每个事务分配一个递增的, int32 整型 数作为 唯一的事务ID, 即 xid. 。

PostgreSQL 内部数据结构中, 每个元组(行记录) 有 4 个与事务可见性相关的 **隐藏列**:

- xmin, 创建该行数据的 xid;
- xmax, 删除改行的xid;
- cmin, 插入该元组的命令在事务中的命令序列号;
- cmax, 删除该元组的命令在事务中的命令序列号.

